{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c86fd748-39ed-4b78-937f-4172c4b5215a",
   "metadata": {},
   "source": [
    "# Fine-tuning a model for music classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d303dfa-3825-4f7c-a56e-5beb3b71eeca",
   "metadata": {},
   "source": [
    "## The dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0f130b-f5d3-41c8-8ba3-60cee214c880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "gtzan = load_dataset(\"marsyas/gtzan\", \"all\")\n",
    "gtzan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efef653-0dc5-4f36-bf4e-dd0d7cde6af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtzan = gtzan[\"train\"].train_test_split(seed=42, shuffle=True, test_size=0.1)\n",
    "gtzan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d858ea1-7632-4a9b-aeb0-f5a7703d4660",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtzan[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55fb496-a939-42a6-8ad1-6f4eb451da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label_fn = gtzan[\"train\"].features[\"genre\"].int2str\n",
    "id2label_fn(gtzan[\"train\"][0][\"genre\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6b3c2a-0cf0-48a6-8f4e-88b4fd11659e",
   "metadata": {},
   "source": [
    "## Picking a pretrained model for audio classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127ac0d4-1401-409a-88a8-1105b502e83f",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19001e5f-13dc-428e-bbe2-612a2a1be38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "model_id = \"ntu-spml/distilhubert\"\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\n",
    "    model_id, do_normalize=True, return_attention_mask=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e62643b-b927-4089-9d9e-c8167412a4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = feature_extractor.sampling_rate\n",
    "sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6036e5a2-e070-4110-a8b8-fe372eb3312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "\n",
    "gtzan = gtzan.cast_column(\"audio\", Audio(sampling_rate=sampling_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fb9a35-b903-407f-beb8-48cb98c8e90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtzan[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827d5932-be5a-41e8-b632-a78686832844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "sample = gtzan[\"train\"][0][\"audio\"]\n",
    "\n",
    "print(f\"Mean: {np.mean(sample['array']):.3}, Variance: {np.var(sample['array']):.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad97b8e7-102a-4284-9e2f-d6b2fa8a8438",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = feature_extractor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"])\n",
    "\n",
    "print(f\"inputs keys: {list(inputs.keys())}\")\n",
    "\n",
    "print(\n",
    "    f\"Mean: {np.mean(inputs['input_values']):.3}, Variance: {np.var(inputs['input_values']):.3}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51bdc6f-cabf-49ac-a7db-029e55496b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_duration = 30.0\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n",
    "    inputs = feature_extractor(\n",
    "        audio_arrays,\n",
    "        sampling_rate=feature_extractor.sampling_rate,\n",
    "        max_length=int(feature_extractor.sampling_rate * max_duration),\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "    )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab377c60-3f37-481c-af25-cd9fcc7f610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtzan_encoded = gtzan.map(\n",
    "    preprocess_function,\n",
    "    remove_columns=[\"audio\", \"file\"],\n",
    "    batched=True,\n",
    "    batch_size=100,\n",
    "    num_proc=1,\n",
    ")\n",
    "gtzan_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d509f1f-5df6-4ee2-a875-6e01cbbc75cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtzan_encoded = gtzan_encoded.rename_column(\"genre\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9bdba8-3767-47e6-8520-5f1d9aae2c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {\n",
    "    str(i): id2label_fn(i)\n",
    "    for i in range(len(gtzan_encoded[\"train\"].features[\"label\"].names))\n",
    "}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "id2label[\"7\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad79f44-6212-4a66-9ded-f733ddd06600",
   "metadata": {},
   "source": [
    "### Fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579081a6-7739-47e9-94f6-93742e35c3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForAudioClassification\n",
    "\n",
    "num_labels = len(id2label)\n",
    "\n",
    "model = AutoModelForAudioClassification.from_pretrained(\n",
    "    model_id,\n",
    "    num_labels=num_labels,\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b500cdae-80e6-4615-b04d-905a5ff8ff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a330e6-8a78-4d1b-a8d6-c88084d78225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "model_name = model_id.split(\"/\")[-1]\n",
    "batch_size = 8\n",
    "gradient_accumulation_steps = 1\n",
    "num_train_epochs = 10\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-gtzan\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=5,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    fp16=False,\n",
    "    push_to_hub=tRUE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62801b0-161e-40aa-847c-39c14f365f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Computes accuracy on a batch of predictions\"\"\"\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=eval_pred.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56cfdbf-ce74-4de1-82eb-2ae4f3cab461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=gtzan_encoded[\"train\"],\n",
    "    eval_dataset=gtzan_encoded[\"test\"],\n",
    "    tokenizer=feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de1bcc2-fbd9-4f89-8b59-154a6c194ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # push results to Huggingface\n",
    "# kwargs = {\n",
    "#     \"dataset_tags\": \"marsyas/gtzan\",\n",
    "#     \"dataset\": \"GTZAN\",\n",
    "#     \"model_name\": f\"{model_name}-finetuned-gtzan\",\n",
    "#     \"finetuned_from\": model_id,\n",
    "#     \"tasks\": \"audio-classification\",\n",
    "# }\n",
    "\n",
    "# trainer.push_to_hub(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23954ff8-a2cb-4475-b537-1388d2d6d9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
